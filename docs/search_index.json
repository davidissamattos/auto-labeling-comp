[
["index.html", "Automatic labeling comparisson Preface Compiling this document", " Automatic labeling comparisson Teodor Fredriksson, David Issa Mattos, Jan Bosch, Helena Holmström Olsson 09 September, 2020 Preface This is the analysis of the paper The environment was defined and based on the renv package. The renv package logs all the packages in the renv.lock file and manages installation for a specific project. For more information see documentation for renv To replicate this environment, after downloading this repository, type: renv::hydrate() This command will download and install all the the packages use in this work. Note that it will install the packages only for this project. Compiling this document This document was created with the bookdown package. To compile it (and run every command to generate the models, figures and etc. ) type: bookdown::render_book(&#39;index.Rmd&#39;, &#39;all&#39;) or alternatively use the custom function from the utils.R file. compile_book() "],
["data-preparation.html", "Chapter 1 Data preparation 1.1 Merging 20news 1.2 Merging corpus 1.3 Merging cifar 1.4 Merging digits 1.5 merging wine 1.6 merging iris", " Chapter 1 Data preparation Reading the (full) csv for each data set. To each dataset we will add three columns. 1- Indicating the data set 2- Indicating the type of dataset 3- Indicating if we are measuring accuracy or time To add new datasets is basically just adding chunks here. If adding new algorithms it can be added as a new dataset if there is no repeated algorithms.. 1.1 Merging 20news d &lt;- read_csv(&#39;./data/parts/20news_full_acc.csv&#39;) %&gt;% mutate(Dataset=&#39;20news&#39;, DatasetType=&#39;Text&#39;, ValueType=&#39;Accuracy&#39;) %&gt;% dplyr::rename(Value=Accuracy) %&gt;% dplyr::select(-X1) dtemp &lt;- read_csv(&#39;./data/parts/20news_full_time.csv&#39;) %&gt;% mutate(Dataset=&#39;20news&#39;, DatasetType=&#39;Text&#39;, ValueType=&#39;Time&#39;) %&gt;% dplyr::rename(Value=Time) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) 1.2 Merging corpus dtemp &lt;- read_csv(&#39;./data/parts/corpus_full_acc.csv&#39;) %&gt;% mutate(Dataset=&#39;corpus&#39;, DatasetType=&#39;Text&#39;, ValueType=&#39;Accuracy&#39;) %&gt;% dplyr::rename(Value=Accuracy) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) dtemp &lt;- read_csv(&#39;./data/parts/corpus_full_time.csv&#39;) %&gt;% mutate(Dataset=&#39;corpus&#39;, DatasetType=&#39;Text&#39;, ValueType=&#39;Time&#39;) %&gt;% dplyr::rename(Value=Time) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) 1.3 Merging cifar dtemp &lt;- read_csv(&#39;./data/parts/cifar_full_acc.csv&#39;) %&gt;% mutate(Dataset=&#39;cifar&#39;, DatasetType=&#39;Image&#39;, ValueType=&#39;Accuracy&#39;) %&gt;% dplyr::rename(Value=Accuracy) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) dtemp &lt;- read_csv(&#39;./data/parts/cifar_full_time.csv&#39;) %&gt;% mutate(Dataset=&#39;cifar&#39;, DatasetType=&#39;Image&#39;, ValueType=&#39;Time&#39;) %&gt;% dplyr::rename(Value=Time) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) 1.4 Merging digits dtemp &lt;- read_csv(&#39;./data/parts/digits_full_acc.csv&#39;) %&gt;% mutate(Dataset=&#39;digits&#39;, DatasetType=&#39;Image&#39;, ValueType=&#39;Accuracy&#39;) %&gt;% dplyr::rename(Value=Accuracy) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) dtemp &lt;- read_csv(&#39;./data/parts/digits_full_time.csv&#39;) %&gt;% mutate(Dataset=&#39;digits&#39;, DatasetType=&#39;Image&#39;, ValueType=&#39;Time&#39;) %&gt;% dplyr::rename(Value=Time) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) 1.5 merging wine dtemp &lt;- read_csv(&#39;./data/parts/wine_full_acc.csv&#39;) %&gt;% mutate(Dataset=&#39;wine&#39;, DatasetType=&#39;Numerical&#39;, ValueType=&#39;Accuracy&#39;) %&gt;% dplyr::rename(Value=Accuracy) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) dtemp &lt;- read_csv(&#39;./data/parts/wine_full_time.csv&#39;) %&gt;% mutate(Dataset=&#39;wine&#39;, DatasetType=&#39;Numerical&#39;, ValueType=&#39;Time&#39;) %&gt;% dplyr::rename(Value=Time) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) 1.6 merging iris dtemp &lt;- read_csv(&#39;./data/parts/iris_full_acc.csv&#39;) %&gt;% mutate(Dataset=&#39;iris&#39;, DatasetType=&#39;Numerical&#39;, ValueType=&#39;Accuracy&#39;) %&gt;% dplyr::rename(Value=Accuracy) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) dtemp &lt;- read_csv(&#39;./data/parts/iris_full_time.csv&#39;) %&gt;% mutate(Dataset=&#39;iris&#39;, DatasetType=&#39;Numerical&#39;, ValueType=&#39;Time&#39;) %&gt;% dplyr::rename(Value=Time) %&gt;% dplyr::select(-X1) d&lt;-bind_rows(d,dtemp) "],
["correcting-a-few-typos-in-the-dataset-and-doing-some-renaming.html", "Chapter 2 Correcting a few typos in the dataset and doing some renaming", " Chapter 2 Correcting a few typos in the dataset and doing some renaming d&lt;- d %&gt;% dplyr::mutate( model=dplyr::recode(d$model,labeldpreadrbf=&#39;labelspreadrbf&#39;) ) Deleting the temporary dataframe rm(dtemp) "],
["saving-the-csv-dataset.html", "Chapter 3 Saving the csv dataset", " Chapter 3 Saving the csv dataset write_csv(d, &#39;./data/auto-label-comparison.csv&#39;) "],
["analysis.html", "Chapter 4 Analysis 4.1 Ranking accuracy 4.2 Bradley terry model for ranking", " Chapter 4 Analysis d &lt;- read_csv(&#39;./data/auto-label-comparison.csv&#39;) dtime &lt;- dplyr::filter(d, ValueType==&#39;Time&#39;) dacc &lt;- dplyr::filter(d, ValueType==&#39;Accuracy&#39;) 4.1 Ranking accuracy This is just an example on how to analyze the data. I will be using bayesian data analysis here…. 4.1.1 Descriptive statistics 4.1.1.1 Generate some tables Using the latex option you can generate the latex table automatically You can either copy and paste to latex or save it in a separate file and import it… dacc %&gt;% dplyr::group_by(model, DatasetType) %&gt;% summarise(Mean = mean(Value), Median = median(Value)) %&gt;% dplyr::ungroup() %&gt;% #Now is just formating the dataframe to look like a nice table tidyr::pivot_wider(names_from = DatasetType, values_from=c(&#39;Mean&#39;, &#39;Median&#39;)) %&gt;% kable(col.names = c(&quot;Model&quot;,&#39;Image&#39;, &#39;Numerical&#39;, &#39;Text&#39;, &#39;Image&#39;, &#39;Numerical&#39;, &#39;Text&#39;)) %&gt;% #There is the format option of add_header_above(c(&quot; &quot;, &quot;Mean&quot;=3, &quot;Median&quot;=3)) %&gt;% kable_styling() Mean Median Model Image Numerical Text Image Numerical Text labelpropknn 0.1803436 0.4990864 0.3053600 0.0248602 0.3768728 0.3333333 labelproprbf 0.0180183 0.5667558 0.5160357 0.0180183 0.5349159 0.5265126 labelspreadknn 0.5701876 0.8331190 0.8462853 0.6192536 0.8264811 0.8285170 labelspreadrbf 0.6861312 0.7954410 0.2511023 0.7884933 0.8410380 0.3333333 QBC 0.5575380 0.9470665 0.8198721 0.5897392 0.9449465 0.8292117 random 0.5545589 0.9324540 0.7882019 0.5958778 0.9439340 0.7618463 uncertainty 0.5592158 0.9642017 0.8241434 0.5903052 0.9669744 0.8263763 4.1.1.2 Generate some basic plots Just to illustrate here some options Aggregated by type of dataset ggplot(data=dacc, aes(x=model, y=Value, fill=model))+ geom_boxplot()+ theme(axis.text.x = element_blank())+ #remove the x labels facet_wrap(~DatasetType)+ labs(title = &#39;Box-plots for the accuracy&#39;) By individual datasets ggplot(data=dacc, aes(x=model, y=Value, fill=model))+ geom_boxplot()+ theme(axis.text.x = element_blank())+ #remove the x labels facet_wrap(~Dataset)+ labs(title = &#39;Box-plots for the accuracy&#39;) 4.2 Bradley terry model for ranking To create a Bradley terry model we need first to transform our dataset to paired comparisons On each iteration for each dataset for each variable we will rank the models based on the Value of the accuracy (lower accuracy -&gt; smaller) After we expand it to wide so we can compare each algorithm with each other and create a BT dataset d_acc_rank &lt;- dacc %&gt;% dplyr::group_by(Dataset, Variable, iterations) %&gt;% dplyr::mutate(Rank=rank(Value, ties.method = &#39;random&#39;)) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-Value) %&gt;% #we need to drop the Value variable to pivot wider tidyr::pivot_wider(names_from = model, values_from=Rank) Now we can create the BT dataset #a vector with the name of the algorithms models &lt;- get_index_names_as_array(d$model) n_models = length(models) comb &lt;- gtools::combinations(n=n_models, r=2, v=seq(1:n_models), repeats.allowed = F) #all teh paired combinations d_acc_bt &lt;- dplyr::tribble(~model0_name, ~model0, ~model1_name, ~model1, ~y, ~iterations, ~Dataset, ~DatasetType) #now we loop each row of the rank wide dataset and create a new one for(i in 1:nrow(d_acc_rank)) { current_row &lt;- d_acc_rank[i,] for(j in 1:nrow(comb)){ comb_row &lt;- comb[j,] model0_name &lt;- models[comb_row[1]] model0 &lt;- comb_row[1] model0_rank &lt;- current_row[[1,model0_name]] model1_name &lt;- models[comb_row[2]] model1 &lt;- comb_row[2] model1_rank &lt;- current_row[[1,model1_name]] diff_rank &lt;- model1_rank - model0_rank #SInce higher accuracy is better if model 1 rank- model 0 rank is positive than model1 wins and y=1 else y=0 y &lt;- ifelse(diff_rank&gt;0, 1, 0) d_acc_bt &lt;-d_acc_bt %&gt;% add_row(model0_name=model0_name, model0=model0, model1_name=model1_name, model1=model1, y=y, iterations=current_row$iterations, Dataset=current_row$Dataset, DatasetType=current_row$DatasetType) } } Now that we have the dataset we can run the model print_stan_code(&#39;./models/rankingmodel.stan&#39;) // Ranking model // Author: David Issa Mattos // Date: 6 sept 2020 // // data { int &lt;lower=1&gt; N_total; // Sample size int y[N_total]; //variable that indicates which one wins model 0 or model 1 int &lt;lower=1&gt; N_models; // Number of models int &lt;lower=1&gt; model0[N_total]; int &lt;lower=1&gt; model1[N_total]; // //To model the influence of each benchmark // int &lt;lower=1&gt; N_bm; // int bm_id[N_total]; } parameters { real a_model[N_models]; //Latent variable that represents the strength value of each model } model { real p[N_total]; a_model ~ normal(0,2); for (i in 1:N_total) { p[i] = a_model[model0[i]] - a_model[model1[i]]; } y ~ bernoulli_logit(p); } //Uncoment this part to get the posterior predictives and the log likelihood //But note that it takes a lot of space in the final model // generated quantities{ // vecor [N_total] y_rep; // vector[N_total] log_lik; // for(i in 1:N_total){ // real p; // p = a_alg[algo1[i]] - a_alg[algo0[i]]; // y_rep[i] = bernoulli_logit_rng(p); // // //Log likelihood // log_lik[i] = bernoulli_logit_lpmf(y[i] | p); // } // } m1_data &lt;- list( N_total=nrow(d_acc_bt), y = as.integer(d_acc_bt$y), N_models = as.integer(n_models), model0=as.integer(d_acc_bt$model0), model1=as.integer(d_acc_bt$model1) ) Note that this is a stat model for ranking all the accuracy for all models. We can later sophisticate it a bit more but this should be more than enough for a conference m1_fit &lt;- stan(file = &#39;./models/rankingmodel.stan&#39;, data=m1_data, chains = 4, warmup = 200, iter = 2000) saveRDS(m1_fit, file = &quot;./data/m1_fit.RDS&quot;) m1_fit &lt;-readRDS(&quot;./data/m1_fit.RDS&quot;) a_model &lt;- c(&quot;a_model[1]&quot;, &quot;a_model[2]&quot;, &quot;a_model[3]&quot;, &quot;a_model[4]&quot;, &quot;a_model[5]&quot;, &quot;a_model[6]&quot;, &quot;a_model[7]&quot;) rstan::traceplot(m1_fit, pars=a_model) hpdi &lt;- get_HPDI_from_stanfit(m1_fit) hpdi_algorithm &lt;- hpdi %&gt;% dplyr::filter(str_detect(Parameter, &quot;a_model\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=models) ggplot(data=hpdi_algorithm, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;Estimate&quot;, x=&quot;Model&quot;, title = &quot;HPDI interval of the strength of the model&quot;)+ coord_flip() Here we are extracting all samples and ranking them to have a distribution of the ranks posterior &lt;- rstan::extract(m1_fit) a_model &lt;- as_tibble(posterior$a_model) colnames(a_model) &lt;- models #sampling from the posterior s &lt;- dplyr::sample_n(a_model, size = 1000, replace=T) s &lt;- dplyr::mutate(s, rown = row_number()) wide_s &lt;- tidyr::pivot_longer(s, cols=all_of(models), names_to = &quot;Models&quot;, values_to = &quot;a_model&quot;) rank_df &lt;- wide_s %&gt;% dplyr::group_by(rown) %&gt;% dplyr::mutate(Rank = rank(-a_model, ties.method = &#39;random&#39;)) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-a_model) %&gt;% dplyr::group_by(Models) %&gt;% dplyr::summarise(MedianRank = median(Rank), VarianceRank = var(Rank)) %&gt;% dplyr::arrange(MedianRank) rank_df_table &lt;- rank_df colnames(rank_df_table) &lt;- c(&quot;Models&quot;,&quot;Median Rank&quot;, &quot;Variance of the Rank&quot;) kable(rank_df_table, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&#39;striped&#39;,&quot;hover&quot;, &quot;condensed&quot; )) Models Median Rank Variance of the Rank labelpropknn 1 0.0000000 labelproprbf 2 0.0000000 labelspreadrbf 3 0.0000000 random 4 0.0158198 QBC 5 0.2636627 labelspreadknn 6 0.4159199 uncertainty 7 0.4084795 "]
]
